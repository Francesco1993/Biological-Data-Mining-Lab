{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrative analysis of pathway deregulation in obesity #\n",
    "\n",
    "## Python implementation\n",
    "\n",
    "### Steps (according to the paper)\n",
    "\n",
    "1. Probes containing missing values are excluded from the analysis. \n",
    "\n",
    "2. Probes are mapped to Entrez ID labels if they are available in the associated platform. Otherwise the David portal is used to convert the available labels to Entrez ID labels. \n",
    "\n",
    "3. Values corresponding to raw expression counts or gene expression intensity are log2 transformed (if necessary). \n",
    "\n",
    "4. Probes mapping to the same Entrez ID label are averaged out. \n",
    "\n",
    "5. Probes that cannot be mapped to a unique Entrez ID label are excluded from the analysis, as well as those that cannot be mapped to any Entrez ID label at all. \n",
    "\n",
    "6. We apply a simple L1 normalization in linear space, imposing that the sum of expression of all genes is constant among samples. After these steps, each data set or batch is represented by a single expression matrix X. Each entry Xi j represents the log2 of the expression intensity of gene i in sample j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import std libraries\n",
    "import os\n",
    "from operator import itemgetter \n",
    "import re\n",
    "\n",
    "# Import third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GEOparse\n",
    "\n",
    "# Set logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logging.getLogger(\"GEOparse\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Download the dataset (if needed) and load it.\n",
    "\n",
    "Some GEOparse names:\n",
    "- DataSet (GDS)\n",
    "- Series (GSE)\n",
    "- Platform (GPL)\n",
    "- Samples (GSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading from ./GSE26637_family.soft.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/GEOparse/GEOparse.py:502: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gpls[entry_name] = parse_GPL(data_group, entry_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset_id):\n",
    "    \"\"\"\n",
    "    Load the dataset from disk (or download it if it does not exists)\n",
    "    Arguments:\n",
    "    - dataset_id: the ID of the dataset to load\n",
    "    \n",
    "    Output:\n",
    "    - GSE object (GEOparse Series)\n",
    "    \"\"\"\n",
    "    path = \"./\" + dataset_id + \"_family.soft.gz\"\n",
    "    if os.path.exists(path):\n",
    "        # Load from an existing file\n",
    "        print(\"- Loading from\", path)\n",
    "        gse = GEOparse.get_GEO(filepath=path)\n",
    "    else:\n",
    "        # Download GSE and load it\n",
    "        print(\"- Downloading\", dataset_id)\n",
    "        gse = GEOparse.get_GEO(geo=dataset_id, destdir=\"./\")\n",
    "    return gse\n",
    "\n",
    "dataset_id = \"GSE26637\"\n",
    "gse = load_dataset(dataset_id)\n",
    "print(\"- Dataset loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Info\n",
    "\n",
    "Get some useful info and statistics from our data.\n",
    "\n",
    "We're going to extract:\n",
    "- number of platforms\n",
    "- number of samples\n",
    "- dimension of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of platforms 1\n",
      "- Number of samples 20 Remember, all Female in this daaset\n",
      "- Dimension of each sample (assuming are all the same) (54675, 2)\n",
      "\n",
      "Example of a sample dataframe:\n",
      "(54675, 2)\n",
      "['GSM655612_LF', 'GSM655610_LF', 'GSM655614_OF', 'GSM655621_LF', 'GSM655617_OF', 'GSM655606_OF', 'GSM655603_OF', 'GSM655615_OF', 'GSM655618_LF', 'GSM655619_LF', 'GSM655607_OF', 'GSM655622_LF', 'GSM655620_LF', 'GSM655613_OF', 'GSM655608_LF', 'GSM655609_LF', 'GSM655616_OF', 'GSM655605_OF', 'GSM655604_OF', 'GSM655611_LF']\n",
      "[('GSM655612', 'Insulin Sensitive 7'), ('GSM655610', 'Insulin Sensitive 4'), ('GSM655614', 'Insulin Resistant 14'), ('GSM655621', 'Insulin Sensitive 5'), ('GSM655617', 'Insulin Resistant 9'), ('GSM655606', 'Insulin Resistant 21'), ('GSM655603', 'Insulin Resistant 1'), ('GSM655615', 'Insulin Resistant 20'), ('GSM655618', 'Insulin Sensitive 13'), ('GSM655619', 'Insulin Sensitive 3'), ('GSM655607', 'Insulin Resistant 9'), ('GSM655622', 'Insulin Sensitive 7'), ('GSM655620', 'Insulin Sensitive 4'), ('GSM655613', 'Insulin Resistant 1'), ('GSM655608', 'Insulin Sensitive 13'), ('GSM655609', 'Insulin Sensitive 3'), ('GSM655616', 'Insulin Resistant 21'), ('GSM655605', 'Insulin Resistant 20'), ('GSM655604', 'Insulin Resistant 14'), ('GSM655611', 'Insulin Sensitive 5')]\n"
     ]
    }
   ],
   "source": [
    "# data_frames contains the data-frame of each sample\n",
    "# samples_name is a list which contains the name associated to each dataframe\n",
    "data_frames = []\n",
    "samples_information = []\n",
    "\n",
    "#this variable is not used but will help in finding elements that are correlated in the original experiment\n",
    "association_dictio = {}\n",
    "\n",
    "for gsm_name, gsm in gse.gsms.items():\n",
    "    #print(gsm.metadata)\n",
    "    list_identifier = gsm.metadata['title'][0].split()\n",
    "    identifier = list_identifier[1] + \" \" + list_identifier[2] + \" \" + list_identifier[3]\n",
    "    if not identifier in association_dictio.keys():\n",
    "        association_dictio[identifier] = []\n",
    "    if identifier in association_dictio.keys():\n",
    "        association_dictio[identifier].append((gsm.table, gsm.metadata['geo_accession'][0]))\n",
    "        \n",
    "    data_frames.append(gsm.table)\n",
    "    samples_information.append((gsm.metadata['geo_accession'][0], identifier))\n",
    "    #print(gsm_name)\n",
    "\n",
    "samples_information_reduced = []\n",
    "for el in samples_information:\n",
    "    if \"Sensitive\" in el[1]:\n",
    "        samples_information_reduced.append(el[0] + \"_\" + \"LF\")\n",
    "    elif \"Resistant\" in el[1]:\n",
    "        samples_information_reduced.append(el[0] + \"_\" + \"OF\")\n",
    "\n",
    "print(\"- Number of platforms\", len(gse.gpls.items()))\n",
    "print(\"- Number of samples\", len(data_frames), \"Remember, all Female in this daaset\")\n",
    "print(\"- Dimension of each sample (assuming are all the same)\", data_frames[0].shape)\n",
    "print('\\nExample of a sample dataframe:')\n",
    "data_frames[0].head()\n",
    "print(data_frames[0].shape)\n",
    "print(samples_information_reduced)\n",
    "print(samples_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data #1\n",
    "\n",
    "We're going to:\n",
    "- Remove probes from the mapper, mapping to multiple Entrez IDs\n",
    "- Construct a Python dictionary containing the valid probes and their Entrez ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mapper loaded 41834\n"
     ]
    }
   ],
   "source": [
    "def create_mapper(meta_data_tables):\n",
    "    \"\"\"\n",
    "    Returns a python dictionary that represents our mapper object\n",
    "    Important: not all probs_id are mapped to an ENTREZ_GENE_ID\n",
    "    probs_id without an enterez_id are not added to the dictionary\n",
    "    \"\"\"\n",
    "    mapper = {}\n",
    "    for df in meta_data_tables:\n",
    "        for index, row in df.iterrows():\n",
    "            probs_id = row['ID']\n",
    "            \n",
    "            if probs_id in mapper and mapper[probs_id] != row['ENTREZ_GENE_ID']:\n",
    "                # Multiple enterez id for the same probs\n",
    "                # Set their value to None to invalid them\n",
    "                # Elements set to \"None\" are then removed\n",
    "                mapper[probs_id] = None\n",
    "                \n",
    "            if probs_id not in mapper and not pd.isnull(row['ENTREZ_GENE_ID']):\n",
    "                mapper[probs_id] = row['ENTREZ_GENE_ID']\n",
    "            \n",
    "    # Remove invalid mapping (value = None)\n",
    "    # (Some of the probes are linked with multiple numbers (enterez_id ?) using /// as separator)\n",
    "    filtered_mapper = {k:v for k,v in mapper.items() if v != None and '/' not in v}\n",
    "    \n",
    "    return filtered_mapper\n",
    "\n",
    "meta_data_tables = []\n",
    "for gpl_name, gpl in gse.gpls.items():\n",
    "    meta_data_tables.append(gpl.table)\n",
    "\n",
    "mapper = create_mapper(meta_data_tables)\n",
    "print(\"- Mapper loaded\", len(mapper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data #2: \n",
    "#### Remove rows without a matching enterez_id\n",
    "Intuition: \n",
    "1. Convert the dictionary **mapper** into a pandas' DataFrame (**mapper_df**).  \n",
    "2. Use a SQL-like inner join to merge **mapper_df** with the existing pandas' DataFrame.  \n",
    "Inner join creates a new Dataframe with *only* the matching rows.\n",
    "\n",
    "References:\n",
    "- https://www.w3schools.com/sql/sql_join_inner.asp\n",
    "- https://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of the obtained Pandas DataFrame:\n",
      "            ENTREZ_GENE_ID\n",
      "ID_REF                    \n",
      "228401_at            29028\n",
      "234342_at            56975\n",
      "202971_s_at           8445\n",
      "1553668_at           84859\n",
      "236655_at             7163\n"
     ]
    }
   ],
   "source": [
    "# Convert mapper to a Pandas Dataframe with two columns (probs, enterez_id)\n",
    "mapper_df = pd.DataFrame.from_dict(mapper, orient='index')\n",
    "mapper_df.index.name = 'ID_REF'\n",
    "mapper_df.columns = ['ENTREZ_GENE_ID']\n",
    "print(\"\\nExample of the obtained Pandas DataFrame:\")\n",
    "print(mapper_df.head())\n",
    "\n",
    "# Create a mapper (sample_id, person_id)\n",
    "#mapper_sample_person = pd.DataFrame(samples_label)\n",
    "#mapper_sample_person = mapper_sample_person.set_index([samples_name])\n",
    "#mapper_sample_person = mapper_sample_person.transpose()\n",
    "#mapper_sample_person.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a Dataframe Entrez ID - Value: genes common to all array\n",
    "For each sample:\n",
    "1. We convert probes' values in **log2(values)**\n",
    "2. Rows with the same **entrez_id** are merged together using the average (probes mapping to the same Entrez ID are averaged out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before any removal (20486, 20)\n",
      "size after removing genes with missing value (20486, 20)\n",
      "\n",
      "Example of the obtained merged data frame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM655612_LF</th>\n",
       "      <th>GSM655610_LF</th>\n",
       "      <th>GSM655614_OF</th>\n",
       "      <th>GSM655621_LF</th>\n",
       "      <th>GSM655617_OF</th>\n",
       "      <th>GSM655606_OF</th>\n",
       "      <th>GSM655603_OF</th>\n",
       "      <th>GSM655615_OF</th>\n",
       "      <th>GSM655618_LF</th>\n",
       "      <th>GSM655619_LF</th>\n",
       "      <th>GSM655607_OF</th>\n",
       "      <th>GSM655622_LF</th>\n",
       "      <th>GSM655620_LF</th>\n",
       "      <th>GSM655613_OF</th>\n",
       "      <th>GSM655608_LF</th>\n",
       "      <th>GSM655609_LF</th>\n",
       "      <th>GSM655616_OF</th>\n",
       "      <th>GSM655605_OF</th>\n",
       "      <th>GSM655604_OF</th>\n",
       "      <th>GSM655611_LF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTREZ_GENE_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-19.817234</td>\n",
       "      <td>-19.432509</td>\n",
       "      <td>-19.639501</td>\n",
       "      <td>-19.493835</td>\n",
       "      <td>-19.760796</td>\n",
       "      <td>-19.680379</td>\n",
       "      <td>-19.755866</td>\n",
       "      <td>-19.854615</td>\n",
       "      <td>-19.534963</td>\n",
       "      <td>-19.683329</td>\n",
       "      <td>-19.553260</td>\n",
       "      <td>-19.782791</td>\n",
       "      <td>-19.362538</td>\n",
       "      <td>-19.531939</td>\n",
       "      <td>-19.546581</td>\n",
       "      <td>-19.669911</td>\n",
       "      <td>-19.773928</td>\n",
       "      <td>-19.82005</td>\n",
       "      <td>-19.590240</td>\n",
       "      <td>-19.752417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-18.617234</td>\n",
       "      <td>-19.362509</td>\n",
       "      <td>-19.559501</td>\n",
       "      <td>-19.443835</td>\n",
       "      <td>-19.760796</td>\n",
       "      <td>-19.630379</td>\n",
       "      <td>-19.725866</td>\n",
       "      <td>-19.794615</td>\n",
       "      <td>-19.454963</td>\n",
       "      <td>-19.623329</td>\n",
       "      <td>-19.603260</td>\n",
       "      <td>-19.752791</td>\n",
       "      <td>-19.362538</td>\n",
       "      <td>-18.341939</td>\n",
       "      <td>-19.496581</td>\n",
       "      <td>-19.659911</td>\n",
       "      <td>-19.723928</td>\n",
       "      <td>-19.75005</td>\n",
       "      <td>-19.530240</td>\n",
       "      <td>-19.592417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-15.002234</td>\n",
       "      <td>-15.542509</td>\n",
       "      <td>-15.539501</td>\n",
       "      <td>-15.853835</td>\n",
       "      <td>-14.160796</td>\n",
       "      <td>-15.810379</td>\n",
       "      <td>-15.790866</td>\n",
       "      <td>-14.339615</td>\n",
       "      <td>-16.679963</td>\n",
       "      <td>-14.273329</td>\n",
       "      <td>-15.778260</td>\n",
       "      <td>-14.352791</td>\n",
       "      <td>-16.357538</td>\n",
       "      <td>-15.331939</td>\n",
       "      <td>-15.861581</td>\n",
       "      <td>-15.474911</td>\n",
       "      <td>-14.798928</td>\n",
       "      <td>-15.12005</td>\n",
       "      <td>-15.575240</td>\n",
       "      <td>-16.367417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-18.932234</td>\n",
       "      <td>-18.552509</td>\n",
       "      <td>-18.719501</td>\n",
       "      <td>-18.583835</td>\n",
       "      <td>-18.875796</td>\n",
       "      <td>-18.855379</td>\n",
       "      <td>-18.905866</td>\n",
       "      <td>-19.039615</td>\n",
       "      <td>-18.429963</td>\n",
       "      <td>-18.793329</td>\n",
       "      <td>-18.738260</td>\n",
       "      <td>-18.897791</td>\n",
       "      <td>-18.347538</td>\n",
       "      <td>-18.516939</td>\n",
       "      <td>-18.646581</td>\n",
       "      <td>-18.729911</td>\n",
       "      <td>-18.923928</td>\n",
       "      <td>-18.93505</td>\n",
       "      <td>-18.715240</td>\n",
       "      <td>-18.867417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>-17.400091</td>\n",
       "      <td>-16.268223</td>\n",
       "      <td>-16.922358</td>\n",
       "      <td>-16.613835</td>\n",
       "      <td>-16.913653</td>\n",
       "      <td>-16.864665</td>\n",
       "      <td>-16.800152</td>\n",
       "      <td>-16.870329</td>\n",
       "      <td>-17.072106</td>\n",
       "      <td>-16.994757</td>\n",
       "      <td>-16.986117</td>\n",
       "      <td>-17.405648</td>\n",
       "      <td>-17.176823</td>\n",
       "      <td>-16.700510</td>\n",
       "      <td>-16.775153</td>\n",
       "      <td>-17.109911</td>\n",
       "      <td>-16.949642</td>\n",
       "      <td>-17.22005</td>\n",
       "      <td>-16.565955</td>\n",
       "      <td>-16.938131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                GSM655612_LF  GSM655610_LF  GSM655614_OF  GSM655621_LF  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -19.817234    -19.432509    -19.639501    -19.493835   \n",
       "10                -18.617234    -19.362509    -19.559501    -19.443835   \n",
       "100               -15.002234    -15.542509    -15.539501    -15.853835   \n",
       "1000              -18.932234    -18.552509    -18.719501    -18.583835   \n",
       "10000             -17.400091    -16.268223    -16.922358    -16.613835   \n",
       "\n",
       "                GSM655617_OF  GSM655606_OF  GSM655603_OF  GSM655615_OF  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -19.760796    -19.680379    -19.755866    -19.854615   \n",
       "10                -19.760796    -19.630379    -19.725866    -19.794615   \n",
       "100               -14.160796    -15.810379    -15.790866    -14.339615   \n",
       "1000              -18.875796    -18.855379    -18.905866    -19.039615   \n",
       "10000             -16.913653    -16.864665    -16.800152    -16.870329   \n",
       "\n",
       "                GSM655618_LF  GSM655619_LF  GSM655607_OF  GSM655622_LF  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -19.534963    -19.683329    -19.553260    -19.782791   \n",
       "10                -19.454963    -19.623329    -19.603260    -19.752791   \n",
       "100               -16.679963    -14.273329    -15.778260    -14.352791   \n",
       "1000              -18.429963    -18.793329    -18.738260    -18.897791   \n",
       "10000             -17.072106    -16.994757    -16.986117    -17.405648   \n",
       "\n",
       "                GSM655620_LF  GSM655613_OF  GSM655608_LF  GSM655609_LF  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -19.362538    -19.531939    -19.546581    -19.669911   \n",
       "10                -19.362538    -18.341939    -19.496581    -19.659911   \n",
       "100               -16.357538    -15.331939    -15.861581    -15.474911   \n",
       "1000              -18.347538    -18.516939    -18.646581    -18.729911   \n",
       "10000             -17.176823    -16.700510    -16.775153    -17.109911   \n",
       "\n",
       "                GSM655616_OF  GSM655605_OF  GSM655604_OF  GSM655611_LF  \n",
       "ENTREZ_GENE_ID                                                          \n",
       "1                 -19.773928     -19.82005    -19.590240    -19.752417  \n",
       "10                -19.723928     -19.75005    -19.530240    -19.592417  \n",
       "100               -14.798928     -15.12005    -15.575240    -16.367417  \n",
       "1000              -18.923928     -18.93505    -18.715240    -18.867417  \n",
       "10000             -16.949642     -17.22005    -16.565955    -16.938131  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update each df object inside the list 'data_frames' with the dataframe with only matching probs_id\n",
    "# For each sample's dataframes:\n",
    "# - log2\n",
    "# - only matching entrez_id\n",
    "# - L1 normalization\n",
    "data_frames_entrez = []\n",
    "for df in data_frames:\n",
    "    df = pd.merge(df, mapper_df, how='inner', left_on=['ID_REF'], right_index=True, sort=False)\n",
    "    df = df.groupby('ENTREZ_GENE_ID').mean()\n",
    "    df['VALUE'] = 2**df['VALUE']\n",
    "    df.VALUE = df.VALUE / df.VALUE.sum()\n",
    "    df['VALUE'] = np.log2(df['VALUE'])\n",
    "    data_frames_entrez.append(df)\n",
    "\n",
    "\"\"\" part that has to deal with multiple sample for the same person\n",
    "# ok, now we have to concat all the dataframes of each person\n",
    "data_frames_per_person = []\n",
    "\n",
    "# remove repeated elements from samples_label\n",
    "unique_person_label = list(set(samples_label))\n",
    "\n",
    "for person_label in unique_person_label:\n",
    "    \n",
    "    # get index of repeated elements in samples_label that has the value = person_label\n",
    "    index_to_merge = [i for i, x in enumerate(samples_label) if x == person_label]\n",
    "    \n",
    "    # get elements from data_frames_entrez given the index in index_to_merge\n",
    "    arrays = list(itemgetter(*index_to_merge)(data_frames_entrez))\n",
    "    \n",
    "    # if arrays contains the same subset of entrez_id, do the mean\n",
    "    all_gene_person = pd.concat(arrays).groupby('ENTREZ_GENE_ID').mean()\n",
    "    \n",
    "    # save the dataset with all the 5 arrays inside data_frames_per_person\n",
    "    data_frames_per_person.append(all_gene_person)\n",
    "\"\"\"\n",
    "\n",
    "# concat data_frames by columns and use the sample GSM identifier as axis\n",
    "merged_entrez_value_df = pd.concat(data_frames_entrez, axis=1, keys=samples_information_reduced)\n",
    "print(\"size before any removal\", merged_entrez_value_df.shape)\n",
    "\n",
    "# remove gene with at least 1 missing value\n",
    "merged_entrez_value_df = merged_entrez_value_df.dropna(axis=0, how='any')\n",
    "print(\"size after removing genes with missing value\", merged_entrez_value_df.shape)\n",
    "\n",
    "# remove disturbing index \"VALUE\"\n",
    "merged_entrez_value_df.columns = merged_entrez_value_df.columns.droplevel([1])\n",
    "\n",
    "print(\"\\nExample of the obtained merged data frame:\")\n",
    "merged_entrez_value_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_entrez_value_df.to_pickle(\"data/GSE26637_table.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
