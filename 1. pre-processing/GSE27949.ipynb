{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrative analysis of pathway deregulation in obesity #\n",
    "\n",
    "## Python implementation\n",
    "\n",
    "### Steps (according to the paper)\n",
    "\n",
    "1. Probes containing missing values are excluded from the analysis. \n",
    "\n",
    "2. Probes are mapped to Entrez ID labels if they are available in the associated platform. Otherwise the David portal is used to convert the available labels to Entrez ID labels. \n",
    "\n",
    "3. Values corresponding to raw expression counts or gene expression intensity are log2 transformed (if necessary). \n",
    "\n",
    "4. Probes mapping to the same Entrez ID label are averaged out. \n",
    "\n",
    "5. Probes that cannot be mapped to a unique Entrez ID label are excluded from the analysis, as well as those that cannot be mapped to any Entrez ID label at all. \n",
    "\n",
    "6. We apply a simple L1 normalization in linear space, imposing that the sum of expression of all genes is constant among samples. After these steps, each data set or batch is represented by a single expression matrix X. Each entry Xi j represents the log2 of the expression intensity of gene i in sample j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import std libraries\n",
    "import os\n",
    "from operator import itemgetter \n",
    "import re\n",
    "\n",
    "# Import third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GEOparse\n",
    "\n",
    "# Set logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logging.getLogger(\"GEOparse\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Download the dataset (if needed) and load it.\n",
    "\n",
    "Some GEOparse names:\n",
    "- DataSet (GDS)\n",
    "- Series (GSE)\n",
    "- Platform (GPL)\n",
    "- Samples (GSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading from ./GSE27949_family.soft.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/GEOparse/GEOparse.py:502: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gpls[entry_name] = parse_GPL(data_group, entry_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset_id):\n",
    "    \"\"\"\n",
    "    Load the dataset from disk (or download it if it does not exists)\n",
    "    Arguments:\n",
    "    - dataset_id: the ID of the dataset to load\n",
    "    \n",
    "    Output:\n",
    "    - GSE object (GEOparse Series)\n",
    "    \"\"\"\n",
    "    path = \"./\" + dataset_id + \"_family.soft.gz\"\n",
    "    if os.path.exists(path):\n",
    "        # Load from an existing file\n",
    "        print(\"- Loading from\", path)\n",
    "        gse = GEOparse.get_GEO(filepath=path)\n",
    "    else:\n",
    "        # Download GSE and load it\n",
    "        print(\"- Downloading\", dataset_id)\n",
    "        gse = GEOparse.get_GEO(geo=dataset_id, destdir=\"./\")\n",
    "    return gse\n",
    "\n",
    "dataset_id = \"GSE27949\"\n",
    "gse = load_dataset(dataset_id)\n",
    "print(\"- Dataset loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Info\n",
    "\n",
    "Get some useful info and statistics from our data.\n",
    "\n",
    "We're going to extract:\n",
    "- number of platforms\n",
    "- number of samples\n",
    "- dimension of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of platforms 1\n",
      "- Number of samples 23\n",
      "- Dimension of each sample (assuming are all the same) (54675, 2)\n",
      "\n",
      "Example of a sample dataframe:\n",
      "(54675, 2)\n",
      "['GSM691142_OU', 'GSM691122_OU', 'GSM691127_OU', 'GSM691143_LU', 'GSM691130_OU', 'GSM691136_LU', 'GSM691146_OU', 'GSM691123_OU', 'GSM691128_OU', 'GSM691129_OU', 'GSM691145_OU', 'GSM691132_OU', 'GSM691152_LU', 'GSM691153_LU', 'GSM691138_OU', 'GSM691125_OU', 'GSM691124_OU', 'GSM691151_LU', 'GSM691131_OU', 'GSM691126_OU', 'GSM691154_LU', 'GSM691134_OU', 'GSM691144_OU']\n"
     ]
    }
   ],
   "source": [
    "# data_frames contains the data-frame of each sample\n",
    "# samples_name is a list which contains the name associated to each dataframe\n",
    "data_frames = []\n",
    "samples_information = []\n",
    "for gsm_name, gsm in gse.gsms.items():\n",
    "    #print(gsm.metadata)\n",
    "    email = gsm.metadata['contact_email'][0]\n",
    "    bmi = re.findall('\\d+', gsm.metadata['characteristics_ch1'][1])\n",
    "    bmi = float(bmi[0])\n",
    "    if bmi >= 30:\n",
    "        samples_information.append(gsm_name + \"_\" + \"OU\")\n",
    "        data_frames.append(gsm.table)\n",
    "    elif bmi <= 24.9:\n",
    "        samples_information.append(gsm_name + \"_\" + \"LU\")\n",
    "        data_frames.append(gsm.table)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(\"- Number of platforms\", len(gse.gpls.items()))\n",
    "print(\"- Number of samples\", len(data_frames))\n",
    "print(\"- Dimension of each sample (assuming are all the same)\", data_frames[0].shape)\n",
    "print('\\nExample of a sample dataframe:')\n",
    "data_frames[0].head()\n",
    "print(data_frames[0].shape)\n",
    "print(samples_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data #1\n",
    "\n",
    "We're going to:\n",
    "- Remove probes from the mapper, mapping to multiple Entrez IDs\n",
    "- Construct a Python dictionary containing the valid probes and their Entrez ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mapper loaded 41834\n"
     ]
    }
   ],
   "source": [
    "def create_mapper(meta_data_tables):\n",
    "    \"\"\"\n",
    "    Returns a python dictionary that represents our mapper object\n",
    "    Important: not all probs_id are mapped to an ENTREZ_GENE_ID\n",
    "    probs_id without an enterez_id are not added to the dictionary\n",
    "    \"\"\"\n",
    "    mapper = {}\n",
    "    for df in meta_data_tables:\n",
    "        for index, row in df.iterrows():\n",
    "            probs_id = row['ID']\n",
    "            \n",
    "            if probs_id in mapper and mapper[probs_id] != row['ENTREZ_GENE_ID']:\n",
    "                # Multiple enterez id for the same probs\n",
    "                # Set their value to None to invalid them\n",
    "                # Elements set to \"None\" are then removed\n",
    "                mapper[probs_id] = None\n",
    "                \n",
    "            if probs_id not in mapper and not pd.isnull(row['ENTREZ_GENE_ID']):\n",
    "                mapper[probs_id] = row['ENTREZ_GENE_ID']\n",
    "            \n",
    "    # Remove invalid mapping (value = None)\n",
    "    # (Some of the probes are linked with multiple numbers (enterez_id ?) using /// as separator)\n",
    "    filtered_mapper = {k:v for k,v in mapper.items() if v != None and '/' not in v}\n",
    "    \n",
    "    return filtered_mapper\n",
    "\n",
    "meta_data_tables = []\n",
    "for gpl_name, gpl in gse.gpls.items():\n",
    "    meta_data_tables.append(gpl.table)\n",
    "\n",
    "mapper = create_mapper(meta_data_tables)\n",
    "print(\"- Mapper loaded\", len(mapper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data #2: \n",
    "#### Remove rows without a matching enterez_id\n",
    "Intuition: \n",
    "1. Convert the dictionary **mapper** into a pandas' DataFrame (**mapper_df**).  \n",
    "2. Use a SQL-like inner join to merge **mapper_df** with the existing pandas' DataFrame.  \n",
    "Inner join creates a new Dataframe with *only* the matching rows.\n",
    "\n",
    "References:\n",
    "- https://www.w3schools.com/sql/sql_join_inner.asp\n",
    "- https://pandas.pydata.org/pandas-docs/stable/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of the obtained Pandas DataFrame:\n"
     ]
    }
   ],
   "source": [
    "# Convert mapper to a Pandas Dataframe with two columns (probs, enterez_id)\n",
    "mapper_df = pd.DataFrame.from_dict(mapper, orient='index')\n",
    "mapper_df.index.name = 'ID_REF'\n",
    "mapper_df.columns = ['ENTREZ_GENE_ID']\n",
    "print(\"\\nExample of the obtained Pandas DataFrame:\")\n",
    "\n",
    "# Create a mapper (sample_id, person_id)\n",
    "#mapper_sample_person = pd.DataFrame(samples_label)\n",
    "#mapper_sample_person = mapper_sample_person.set_index([samples_name])\n",
    "#mapper_sample_person = mapper_sample_person.transpose()\n",
    "#mapper_sample_person.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a Dataframe Entrez ID - Value: genes common to all array\n",
    "For each sample:\n",
    "1. We convert probes' values in **log2(values)**\n",
    "2. Rows with the same **entrez_id** are merged together using the average (probes mapping to the same Entrez ID are averaged out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before any removal (20486, 23)\n",
      "size after removing genes with missing value (20486, 23)\n",
      "\n",
      "Example of the obtained merged data frame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM691142_OU</th>\n",
       "      <th>GSM691122_OU</th>\n",
       "      <th>GSM691127_OU</th>\n",
       "      <th>GSM691143_LU</th>\n",
       "      <th>GSM691130_OU</th>\n",
       "      <th>GSM691136_LU</th>\n",
       "      <th>GSM691146_OU</th>\n",
       "      <th>GSM691123_OU</th>\n",
       "      <th>GSM691128_OU</th>\n",
       "      <th>GSM691129_OU</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM691153_LU</th>\n",
       "      <th>GSM691138_OU</th>\n",
       "      <th>GSM691125_OU</th>\n",
       "      <th>GSM691124_OU</th>\n",
       "      <th>GSM691151_LU</th>\n",
       "      <th>GSM691131_OU</th>\n",
       "      <th>GSM691126_OU</th>\n",
       "      <th>GSM691154_LU</th>\n",
       "      <th>GSM691134_OU</th>\n",
       "      <th>GSM691144_OU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTREZ_GENE_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.656284</td>\n",
       "      <td>-16.467288</td>\n",
       "      <td>-16.644595</td>\n",
       "      <td>-16.672241</td>\n",
       "      <td>-16.616464</td>\n",
       "      <td>-16.946165</td>\n",
       "      <td>-16.253565</td>\n",
       "      <td>-16.911198</td>\n",
       "      <td>-17.268633</td>\n",
       "      <td>-17.002634</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.941852</td>\n",
       "      <td>-17.034051</td>\n",
       "      <td>-17.102832</td>\n",
       "      <td>-16.751461</td>\n",
       "      <td>-16.978019</td>\n",
       "      <td>-16.991578</td>\n",
       "      <td>-17.002924</td>\n",
       "      <td>-17.219474</td>\n",
       "      <td>-17.365789</td>\n",
       "      <td>-17.142668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-16.941340</td>\n",
       "      <td>-17.058493</td>\n",
       "      <td>-16.668810</td>\n",
       "      <td>-17.026982</td>\n",
       "      <td>-16.587789</td>\n",
       "      <td>-17.313423</td>\n",
       "      <td>-17.003948</td>\n",
       "      <td>-16.863739</td>\n",
       "      <td>-17.370265</td>\n",
       "      <td>-17.199917</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.768056</td>\n",
       "      <td>-17.188533</td>\n",
       "      <td>-16.889089</td>\n",
       "      <td>-17.086915</td>\n",
       "      <td>-17.200414</td>\n",
       "      <td>-16.900854</td>\n",
       "      <td>-17.292170</td>\n",
       "      <td>-16.936701</td>\n",
       "      <td>-17.048590</td>\n",
       "      <td>-17.194503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-15.335082</td>\n",
       "      <td>-15.143535</td>\n",
       "      <td>-14.966167</td>\n",
       "      <td>-15.173494</td>\n",
       "      <td>-14.668714</td>\n",
       "      <td>-15.262088</td>\n",
       "      <td>-14.900857</td>\n",
       "      <td>-15.211285</td>\n",
       "      <td>-15.049138</td>\n",
       "      <td>-15.427917</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.530176</td>\n",
       "      <td>-14.857492</td>\n",
       "      <td>-14.978559</td>\n",
       "      <td>-15.229336</td>\n",
       "      <td>-15.602385</td>\n",
       "      <td>-14.842609</td>\n",
       "      <td>-15.146958</td>\n",
       "      <td>-14.924284</td>\n",
       "      <td>-15.921903</td>\n",
       "      <td>-15.019982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-16.957133</td>\n",
       "      <td>-16.888659</td>\n",
       "      <td>-17.109824</td>\n",
       "      <td>-17.145079</td>\n",
       "      <td>-17.317420</td>\n",
       "      <td>-17.175075</td>\n",
       "      <td>-16.833997</td>\n",
       "      <td>-16.882759</td>\n",
       "      <td>-17.470116</td>\n",
       "      <td>-17.377273</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.191087</td>\n",
       "      <td>-17.595929</td>\n",
       "      <td>-17.137453</td>\n",
       "      <td>-17.238383</td>\n",
       "      <td>-17.253288</td>\n",
       "      <td>-17.556044</td>\n",
       "      <td>-17.451344</td>\n",
       "      <td>-17.332248</td>\n",
       "      <td>-17.216601</td>\n",
       "      <td>-17.425703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>-15.973645</td>\n",
       "      <td>-15.917606</td>\n",
       "      <td>-15.773719</td>\n",
       "      <td>-16.009637</td>\n",
       "      <td>-15.943373</td>\n",
       "      <td>-15.714638</td>\n",
       "      <td>-15.984475</td>\n",
       "      <td>-16.035525</td>\n",
       "      <td>-16.155986</td>\n",
       "      <td>-16.133969</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.016150</td>\n",
       "      <td>-16.100682</td>\n",
       "      <td>-16.029792</td>\n",
       "      <td>-15.821668</td>\n",
       "      <td>-16.253650</td>\n",
       "      <td>-15.629414</td>\n",
       "      <td>-16.177538</td>\n",
       "      <td>-15.829951</td>\n",
       "      <td>-16.789228</td>\n",
       "      <td>-15.988975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GSM691142_OU  GSM691122_OU  GSM691127_OU  GSM691143_LU  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -16.656284    -16.467288    -16.644595    -16.672241   \n",
       "10                -16.941340    -17.058493    -16.668810    -17.026982   \n",
       "100               -15.335082    -15.143535    -14.966167    -15.173494   \n",
       "1000              -16.957133    -16.888659    -17.109824    -17.145079   \n",
       "10000             -15.973645    -15.917606    -15.773719    -16.009637   \n",
       "\n",
       "                GSM691130_OU  GSM691136_LU  GSM691146_OU  GSM691123_OU  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -16.616464    -16.946165    -16.253565    -16.911198   \n",
       "10                -16.587789    -17.313423    -17.003948    -16.863739   \n",
       "100               -14.668714    -15.262088    -14.900857    -15.211285   \n",
       "1000              -17.317420    -17.175075    -16.833997    -16.882759   \n",
       "10000             -15.943373    -15.714638    -15.984475    -16.035525   \n",
       "\n",
       "                GSM691128_OU  GSM691129_OU      ...       GSM691153_LU  \\\n",
       "ENTREZ_GENE_ID                                  ...                      \n",
       "1                 -17.268633    -17.002634      ...         -16.941852   \n",
       "10                -17.370265    -17.199917      ...         -16.768056   \n",
       "100               -15.049138    -15.427917      ...         -14.530176   \n",
       "1000              -17.470116    -17.377273      ...         -17.191087   \n",
       "10000             -16.155986    -16.133969      ...         -16.016150   \n",
       "\n",
       "                GSM691138_OU  GSM691125_OU  GSM691124_OU  GSM691151_LU  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -17.034051    -17.102832    -16.751461    -16.978019   \n",
       "10                -17.188533    -16.889089    -17.086915    -17.200414   \n",
       "100               -14.857492    -14.978559    -15.229336    -15.602385   \n",
       "1000              -17.595929    -17.137453    -17.238383    -17.253288   \n",
       "10000             -16.100682    -16.029792    -15.821668    -16.253650   \n",
       "\n",
       "                GSM691131_OU  GSM691126_OU  GSM691154_LU  GSM691134_OU  \\\n",
       "ENTREZ_GENE_ID                                                           \n",
       "1                 -16.991578    -17.002924    -17.219474    -17.365789   \n",
       "10                -16.900854    -17.292170    -16.936701    -17.048590   \n",
       "100               -14.842609    -15.146958    -14.924284    -15.921903   \n",
       "1000              -17.556044    -17.451344    -17.332248    -17.216601   \n",
       "10000             -15.629414    -16.177538    -15.829951    -16.789228   \n",
       "\n",
       "                GSM691144_OU  \n",
       "ENTREZ_GENE_ID                \n",
       "1                 -17.142668  \n",
       "10                -17.194503  \n",
       "100               -15.019982  \n",
       "1000              -17.425703  \n",
       "10000             -15.988975  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update each df object inside the list 'data_frames' with the dataframe with only matching probs_id\n",
    "# For each sample's dataframes:\n",
    "# - log2\n",
    "# - only matching entrez_id\n",
    "# - L1 normalization\n",
    "data_frames_entrez = []\n",
    "for df in data_frames:\n",
    "    df = pd.merge(df, mapper_df, how='inner', left_on=['ID_REF'], right_index=True, sort=False)\n",
    "    df = df.groupby('ENTREZ_GENE_ID').mean()\n",
    "    df['VALUE'] = 2**df['VALUE']\n",
    "    df.VALUE = df.VALUE / df.VALUE.sum()\n",
    "    df['VALUE'] = np.log2(df['VALUE'])\n",
    "    data_frames_entrez.append(df)\n",
    "\n",
    "\"\"\" part that has to deal with multiple sample for the same person\n",
    "# ok, now we have to concat all the dataframes of each person\n",
    "data_frames_per_person = []\n",
    "\n",
    "# remove repeated elements from samples_label\n",
    "unique_person_label = list(set(samples_label))\n",
    "\n",
    "for person_label in unique_person_label:\n",
    "    \n",
    "    # get index of repeated elements in samples_label that has the value = person_label\n",
    "    index_to_merge = [i for i, x in enumerate(samples_label) if x == person_label]\n",
    "    \n",
    "    # get elements from data_frames_entrez given the index in index_to_merge\n",
    "    arrays = list(itemgetter(*index_to_merge)(data_frames_entrez))\n",
    "    \n",
    "    # if arrays contains the same subset of entrez_id, do the mean\n",
    "    all_gene_person = pd.concat(arrays).groupby('ENTREZ_GENE_ID').mean()\n",
    "    \n",
    "    # save the dataset with all the 5 arrays inside data_frames_per_person\n",
    "    data_frames_per_person.append(all_gene_person)\n",
    "\"\"\"\n",
    "\n",
    "# concat data_frames by columns and use the people's label as index\n",
    "merged_entrez_value_df = pd.concat(data_frames_entrez, axis=1, keys=samples_information)\n",
    "print(\"size before any removal\", merged_entrez_value_df.shape)\n",
    "\n",
    "# remove gene with at least 1 missing value\n",
    "merged_entrez_value_df = merged_entrez_value_df.dropna(axis=0, how='any')\n",
    "print(\"size after removing genes with missing value\", merged_entrez_value_df.shape)\n",
    "\n",
    "# remove disturbing index \"VALUE\"\n",
    "merged_entrez_value_df.columns = merged_entrez_value_df.columns.droplevel([1])\n",
    "\n",
    "print(\"\\nExample of the obtained merged data frame:\")\n",
    "merged_entrez_value_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_entrez_value_df.to_pickle(\"data/GSE27949_table.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
